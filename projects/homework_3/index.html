<!DOCTYPE html> <html> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Path Tracing | Naman Satish </title> <meta name="author" content="Naman Shimoga Satish"> <meta name="description" content="Part of CS184 : Foundations of Computer Graphics"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%8C%90&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://satish.dev/projects/homework_3/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script src="/assets/js/distillpub/template.v2.js"></script> <script src="/assets/js/distillpub/transforms.v2.js"></script> <script src="/assets/js/distillpub/overrides.js"></script> </head> <body> <d-front-matter> <script async type="text/json">
      {
            "title": "Path Tracing",
            "description": "Part of CS184 : Foundations of Computer Graphics",
            "published": "May 05, 2025",
            "authors": [
              
            ],
            "katex": {
              "delimiters": [
                {
                  "left": "$",
                  "right": "$",
                  "display": false
                },
                {
                  "left": "$$",
                  "right": "$$",
                  "display": true
                }
              ]
            }
          }
    </script> </d-front-matter> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> Naman Satish </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item active"> <a class="nav-link" href="/projects/">projects <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="post distill"> <d-title> <h1>Path Tracing</h1> <p>Part of CS184 : Foundations of Computer Graphics</p> </d-title> <d-article> <d-contents> <nav class="l-text figcaption"> <h3>Contents</h3> <div> <a href="#overview">Overview</a> </div> <div> <a href="#ray-generation-and-scene-intersection">Ray Generation and Scene Intersection</a> </div> <div> <a href="#bounding-volume-hierarchy">Bounding Volume Hierarchy</a> </div> <div> <a href="#direct-illumination">Direct Illumination</a> </div> <div> <a href="#global-illumination">Global Illumination</a> </div> <div> <a href="#adaptive-sampling">Adaptive Sampling</a> </div> </nav> </d-contents> <div class="container l-page"> <h1 id="overview">Overview</h1> <p>Throughout this assignment, we have implemented a path tracer that simulates the interaction of light with a scene. We began by generating rays for each pixel in the image and tracing them through the scene to determine the point’s normal vector. As the number of primitives increased, the computational cost became prohibitive, so we implemented a Bounding Volume Hierarchy (BVH) to efficiently organize the primitives into a tree structure. This optimization allowed us to quickly discard large portions of the scene that do not intersect with the ray, reducing the number of intersection tests required.</p> <p>To achieve accurate color computation, we implemented hemispherical sampling using a Monte Carlo estimator to estimate direct lighting at a point. This method simulated the reflection of light on surfaces and determined the light reflected in the camera’s direction. However, a large number of samples were needed for convergence, so we incorporated importance sampling. This method preferentially sampled points of intersection towards light sources, enabling faster convergence by focusing on regions where light contributions were significant.</p> <p>Despite these improvements, shadowed regions still lacked illumination due to indirect lighting dependencies. To address this, we implemented indirect lighting by recursively tracing rays from intersection points in randomly sampled directions. This simulation of global illumination significantly improved image quality but came with high computational costs. To mitigate these costs, we employed Russian Roulette termination, allowing early termination of some rays based on probability, thus enabling efficient sampling of path lengths. Further, adaptive sampling helped optimize performance by reducing sample counts in regions that converged quickly while increasing them in areas with high variance, ensuring high-quality, low-noise images in reasonable rendering times.</p> <p>This assignment deepened my understanding of rendering complexities and the trade-offs between computational efficiency and image quality. We explored various sampling techniques and their impact on final render quality. Additionally, we learned the significance of acceleration structures like BVH in optimizing ray intersection tests and improving rendering times for complex scenes.</p> <h2 id="ray-generation-and-scene-intersection">Ray Generation and Scene Intersection</h2> <p>The first step in path tracing is to generate rays that simulate light transport in the scene. We start by generating a ray for each pixel in the image, and then we trace the ray through the scene to determine the color of the pixel. The ray generation process involves transforming the pixel coordinates into a ray in world space, and the scene intersection process involves finding the intersection of the ray with the scene geometry.</p> <h3 id="task-1">Task 1</h3> <p>We start by modifiying <code class="language-plaintext highlighter-rouge">Camera::generate_ray(x, y)</code> to generate a ray in world space corresponding to a given normalized image coordinate <code class="language-plaintext highlighter-rouge">(x, y)</code>.</p> <p>Our system is configured as follows: The camera in camera space is positioned at <code class="language-plaintext highlighter-rouge">(0,0,0)</code> and looks along the negative Z-axis. A virtual sensor lies on the <code class="language-plaintext highlighter-rouge">Z = -1</code> plane, spanning the field of view (FOV):</p> <ul> <li> <p>The bottom-left corner of the sensor is located at:</p> \[\left(-\tan\left(\frac{hFov}{2}\right), -\tan\left(\frac{vFov}{2}\right), -1\right)\] </li> <li> <p>The top-right corner is at:</p> \[\left(\tan\left(\frac{hFov}{2}\right), \tan\left(\frac{vFov}{2}\right), -1\right)\] </li> </ul> <p>The input <code class="language-plaintext highlighter-rouge">(x, y)</code> represents normalized image coordinates where:</p> <ul> <li> <code class="language-plaintext highlighter-rouge">(0,0)</code> maps to the bottom-left corner of the sensor</li> <li> <code class="language-plaintext highlighter-rouge">(1,1)</code> maps to the top-right corner</li> </ul> <p>Using linear interpolation, the corresponding sensor space coordinates \((X_s, Y_s, -1)\) are computed as:</p> \[X_s = (2x - 1) \tan\left(\frac{hFov}{2}\right)\] \[Y_s = (2y - 1) \tan\left(\frac{vFov}{2}\right)\] \[Z_s = -1\] <p>The ray originates at the camera’s position in camera space \((0,0,0)\), and its direction is defined by the vector from the camera position to the sensor point:</p> \[\mathbf{d}_{camera} = \left( X_s, Y_s, Z_s \right)\] <p>To ensure the ray direction is a unit vector, it must be normalized:</p> \[\mathbf{d}_{camera} = \frac{\mathbf{d}_{camera}}{\|\mathbf{d}_{camera}\|}\] <p>The camera-to-world transformation matrix \(C_{2W}\) is applied to the ray direction to transform it into world space:</p> \[\mathbf{d}_{world} = C_{2W} \cdot \mathbf{d}_{camera}\] <p>Again, the direction must be normalized:</p> \[\mathbf{d}_{world} = \frac{\mathbf{d}_{world}}{\|\mathbf{d}_{world}\|}\] <p>And finally, we set the ray’s origin, which is simply the camera’s origin in world space:</p> \[\mathbf{o}_{world} = \mathbf{o}_{camera}\] <h3 id="task-2">Task 2</h3> <p>We can now construct multiple rays for a given pixel by sampling uniformly within the pixel’s area. This is done by generating a random offset for each ray within the pixel’s area and adding it to the normalized image coordinates. The ray is then generated using the new coordinates, and we can estimate the overall pixel’s recived radiance by averaging the radiance of all rays.</p> \[\mathbf{offset} = \left( [0,1], [0,1] \right)\] \[\mathbf{r}_i = \text{generate_ray}(x + \mathbf{offset}\_x, y + \mathbf{offset}\_y)\] \[\mathbf{radiance} = \frac{1}{\text{ns_aa}} \sum_{i=1}^{\text{ns_aa}} \text{est}(\mathbf{r}_i)\] <h3 id="task-3">Task 3</h3> <p>Next we can begin with implementing the ray intersection with the scene, starting with triangles. We use the Möller-Trumbore algorithm to determine if a ray intersects a triangle. The algorithm is based on the idea of finding the intersection point of the ray with the plane defined by the triangle, and then checking if the intersection point lies within the triangle.</p> <p>The algorithm is as follows:</p> \[\vec{e}_1 = \vec{p}_1 - \vec{p}_0 \quad \vec{e}_2 = \vec{p}_2 - \vec{p}_0\] \[\vec{s} = \vec{o} - \vec{p}_0 \quad \vec{s}_1 = \vec{d} \times \vec{e}_2 \quad \vec{s}_2 = \vec{s} \times \vec{e}_1\] \[\begin{bmatrix} t \\ b_1 \\ b_2 \end{bmatrix} = \frac{1}{\vec{S}_1 \cdot \vec{E}_1} \begin{bmatrix} \vec{S}_2 \cdot \vec{E}_2 \\ \vec{S}_1 \cdot \vec{S} \\ \vec{S}_2 \cdot \vec{D} \end{bmatrix}\] <p>For the cost of 1 division, 27 multiplications, and 17 additions, we can determine a time at which the ray intersects the triangle (given that the denominator is not zero), and the barycentric coordinates of the intersection point. We can check if the time falls within the interval \([t_{min}, t_{max}]\) and if the barycentric coordinates are within the range \([0, 1]\), and if so we update our ray’s \(t_{max}\) and save information about the intersection. To compute the normal at our intersection, we can use our barycentric coordinates to interpolate each vertex’s normal at the intersection point.</p> <h3 id="task-4">Task 4</h3> <p>Finally, we can implement the ray intersection with spheres. We start off with our definition of a spherical plane \(p:(p-c)^2 - R^2 = 0\). Since we want to find the intersection of the ray and the surface, we can replace \(p\) with our ray formula \(o +td\). This algorithm is based on the idea that we can know there is an intersection at time \(t\) when the distance between the ray at time \(t\) and the sphere’s center is equal to the sphere’s radius. This gives us a quadratic equation in \(t\), which we can solve to find the intersection points.</p> <p>The algorithm is as follows:</p> \[(\mathbf{o} + t\vec{d} - \mathbf{c})^2 - R^2 = 0\] \[(at^2 + bt + c) = 0\] <p>Where:</p> \[a = \vec{d} \cdot \vec{d}\] \[b = 2(\mathbf{o} - \mathbf{c}) \cdot \vec{d}\] \[c = (\mathbf{o} - \mathbf{c}) \cdot (\mathbf{o} - \mathbf{c}) - R^2\] \[\Delta = b^2 - 4ac\] \[t = \frac{-b \pm \sqrt{\Delta}}{2a}\] \[t_{min} = \min(t_1, t_2)\] \[t_{max} = \max(t_1, t_2)\] <p>This will let us determine the intersection time of the ray with the sphere, and we can check if the time falls within the interval \([t_{min}, t_{max}]\) and if so we update our ray’s \(t_{max}\) and save information about the intersection. And we can compute the normal at the intersection point by simply normalizing the vector from the sphere’s center to the intersection point.</p> <h3 id="results">Results</h3> <p>We can now render images with normal shading for a few small .dae files.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs184/hw3/part1_cube-480.webp 480w,/assets/img/cs184/hw3/part1_cube-800.webp 800w,/assets/img/cs184/hw3/part1_cube-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/cs184/hw3/part1_cube.png" width="100%" height="auto" alt="Cube Shading Testing" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption">Cube Shading Testing</div> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs184/hw3/part1_banana-480.webp 480w,/assets/img/cs184/hw3/part1_banana-800.webp 800w,/assets/img/cs184/hw3/part1_banana-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/cs184/hw3/part1_banana.png" width="100%" height="auto" alt="Banana Scene" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption">Banana Scene</div> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs184/hw3/part1_banana_close-480.webp 480w,/assets/img/cs184/hw3/part1_banana_close-800.webp 800w,/assets/img/cs184/hw3/part1_banana_close-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/cs184/hw3/part1_banana_close.png" width="100%" height="auto" alt="Banana Scene Closeup" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption">Banana Scene Closeup</div> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs184/hw3/part1_building-480.webp 480w,/assets/img/cs184/hw3/part1_building-800.webp 800w,/assets/img/cs184/hw3/part1_building-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/cs184/hw3/part1_building.png" width="100%" height="auto" alt="Building Scene" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption">Building Scene</div> </div> </div> <h2 id="bounding-volume-hierarchy">Bounding Volume Hierarchy</h2> <p>The Building Scene above took 161.1159s to render while others like the cube took under a second. The increase in time is due to the increased number of primitives in the scene.</p> <div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">[</span>PathTracer] Input scene file: ../dae/keenan/building.dae
<span class="o">[</span>PathTracer] Rendering using 8 threads
<span class="o">[</span>PathTracer] Collecting primitives... Done! <span class="o">(</span>0.0018 sec<span class="o">)</span>
<span class="o">[</span>PathTracer] Building BVH from 39506 primitives... Done! <span class="o">(</span>0.0003 sec<span class="o">)</span>
<span class="o">[</span>PathTracer] Rendering... 100%! <span class="o">(</span>161.1159s<span class="o">)</span>
<span class="o">[</span>PathTracer] BVH traced 1807017 rays.
<span class="o">[</span>PathTracer] Average speed 0.0112 million rays per second.
<span class="o">[</span>PathTracer] Averaged 8417.173796 intersection tests per ray.
<span class="o">[</span>PathTracer] Saving to file: part1_building.png... Done!
</code></pre></div></div> <p>As the number of primitives in a scene increases, the cost of ray intersection tests can become prohibitively expensive. Currently, we are testing every ray against every primitive in the scene, which results in a time complexity of \(O(n)\), where \(n\) is the number of primitives. To reduce this cost, we can use a Bounding Volume Hierarchy (BVH) to organize the primitives into a tree structure. This allows us to quickly discard large portions of the scene that do not intersect with the ray, reducing the number of intersection tests required, allowing us to achieve a time complexity of \(O(\log n)\).</p> <p>Another example is our cow scene, which took 5.6 seconds to render without BVH acceleration:</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs184/hw3/cow-480.webp 480w,/assets/img/cs184/hw3/cow-800.webp 800w,/assets/img/cs184/hw3/cow-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/cs184/hw3/cow.png" width="100%" height="auto" alt="Cow Scene" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption">Cow Scene</div> </div> </div> <div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">[</span>PathTracer] Input scene file: ../dae/meshedit/cow.dae
<span class="o">[</span>PathTracer] Rendering using 8 threads
<span class="o">[</span>PathTracer] Collecting primitives... Done! <span class="o">(</span>0.0002 sec<span class="o">)</span>
<span class="o">[</span>PathTracer] Building BVH from 5856 primitives... Done! <span class="o">(</span>0.0001 sec<span class="o">)</span>
<span class="o">[</span>PathTracer] Rendering... 100%! <span class="o">(</span>5.6094s<span class="o">)</span>
<span class="o">[</span>PathTracer] BVH traced 473529 rays.
<span class="o">[</span>PathTracer] Average speed 0.0844 million rays per second.
<span class="o">[</span>PathTracer] Averaged 1134.760302 intersection tests per ray.
<span class="o">[</span>PathTracer] Saving to file: cow.png... Done!
<span class="o">[</span>PathTracer] Job completed.
</code></pre></div></div> <h3 id="task-1-1">Task 1</h3> <p>To create our Bounding Volume Hierarchy, we want to create a binary tree where each node represents a bounding box that encloses a set of primitives. We can do this recursively, starting with the root node that encloses all primitives in the scene and splitting the primitives according to a heuristic to create ‘left’ and ‘right’ child nodes. We continue this process until we reach a leaf node that contains a small number of primitives.</p> <p>In my implementation, I first tried to split the primitives along the axis of greatest variance, using the average centroid of the primitives as my splitting point. When I computed the BVH on cow.dae, I had a tree a depth of 13. My next attempt was simpler, where I still chose to split along the axis of greatest variance, but I simply split the primitives in half. This resulted in a tree with a depth of 11.</p> <p>We can visualize differences this heuristic makes by comparing the two trees:</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs184/hw3/half_split-480.webp 480w,/assets/img/cs184/hw3/half_split-800.webp 800w,/assets/img/cs184/hw3/half_split-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/cs184/hw3/half_split.png" width="100%" height="auto" alt="Half Split BVH" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption">Half Split BVH</div> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs184/hw3/variance_split-480.webp 480w,/assets/img/cs184/hw3/variance_split-800.webp 800w,/assets/img/cs184/hw3/variance_split-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/cs184/hw3/variance_split.png" width="100%" height="auto" alt="Variance Split BVH" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption">Variance Split BVH</div> </div> </div> <p>Since we want our BVH to be logarithmic in depth and log2(5856) ~ 12.5, we can say both are reasonable results. However, the half split BVH is more balanced and has a lower depth, which is generally better for performance.</p> <p>I decided to implement a Surface Area Heuristic (SAH) to create a more efficient BVH structure. The SAH heuristic is based on the idea that we want to minimize the cost of traversing the BVH tree, which is a combination of the cost of intersecting the ray with the bounding box and the cost checking the ray against all primitives in each leaf node multiplied by the probability of hitting that leaf node. Therefore, the surface area of the bounding box gives us a good understanding of the probability of hitting that node, so minimizing the overall cost would involve minimizing the surface area of the bounding boxes of the left and right child nodes.</p> <p>I relied on <a href="https://pbr-book.org/3ed-2018/Primitives_and_Intersection_Acceleration/Bounding_Volume_Hierarchies" rel="external nofollow noopener" target="_blank">this textbook</a> for a guide on how the SAH heuristic works and how to implement it in cpp. In my opinion, the assumption that the best axis to split along is the one with the greatest range is a good one, however I believe that variance is a better heuristic than range. This is because variance is a measure of how spread out the data is, and if the data is spread out, it is more likely that a split can be chosen that will separate the data into two distinct groups. This is important because in our SAH heuristic, we want to minimize the surface area of the bounding boxes of the left and right child nodes, and if the data is spread out, it is more likely that a split can be chosen that will separate the data into two distinct groups. I will continue to look into this to determine if my reasoning for using variance is correct.</p> <p>After implementing the SAH heuristic, the depth of the tree was shockingly increased to 16. This is may be due to the fact that the SAH heuristic has more uneven splits as a result of the cost function, which can lead to a deeper tree. Overall the computation cost of a ray intersection test is reduced, while the traversal through the tree may have been increased. This is a tradeoff that is worth it in my opinion, as the cost of ray intersection tests is much higher than the cost of traversing the tree.</p> <p>Let us take a look at the cow split using the SAH heuristic:</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs184/hw3/sah_split-480.webp 480w,/assets/img/cs184/hw3/sah_split-800.webp 800w,/assets/img/cs184/hw3/sah_split-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/cs184/hw3/sah_split.png" width="100%" height="auto" alt="Surface Area Heuristic Split BVH" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption">Surface Area Heuristic Split BVH</div> </div> </div> <h3 id="task-2-1">Task 2</h3> <p>Now we can implement the intersection test for our bounding boxes, this can be simplified for each of the 3 axes, where we check if the ray intersects the bounding box along the axis. We can update the time intervals that our ray intersects the bounding box, which will carry forward information.</p> <h3 id="task-3-1">Task 3</h3> <p>Now we can implement the BVH intersection test, where we traverse the BVH tree to find the closest intersection point. We start at the root node and check if the ray intersects the bounding box of the node. If it does, we check if the node is a leaf node, and if so we test the primitives in the leaf node. If the node is not a leaf node, we recursively test the left and right child nodes. Because our intersection tests update our ray’s time interval, we are left with the closest intersection point.</p> <h3 id="results-1">Results</h3> <p>We can now render images with normal shading for a few large .dae files that we can only render with BVH acceleration.</p> <p>Cow Scene:</p> <div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>❯ ./pathtracer <span class="nt">-t</span> 8 <span class="nt">-r</span> 800 600 <span class="nt">-f</span> cow.png ../dae/meshedit/cow.dae
<span class="o">[</span>PathTracer] Input scene file: ../dae/meshedit/cow.dae
<span class="o">[</span>PathTracer] Rendering using 8 threads
<span class="o">[</span>PathTracer] Collecting primitives... Done! <span class="o">(</span>0.0003 sec<span class="o">)</span>
<span class="o">[</span>PathTracer] Building BVH from 5856 primitives... BVH Depth: 16
Done! <span class="o">(</span>0.0023 sec<span class="o">)</span>
<span class="o">[</span>PathTracer] Rendering... 100%! <span class="o">(</span>0.0388s<span class="o">)</span>
<span class="o">[</span>PathTracer] BVH traced 134568 rays.
<span class="o">[</span>PathTracer] Average speed 3.4652 million rays per second.
<span class="o">[</span>PathTracer] Averaged 4.076385 intersection tests per ray.
<span class="o">[</span>PathTracer] Saving to file: cow.png... Done!
<span class="o">[</span>PathTracer] Job completed.
</code></pre></div></div> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs184/hw3/cow_fast-480.webp 480w,/assets/img/cs184/hw3/cow_fast-800.webp 800w,/assets/img/cs184/hw3/cow_fast-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/cs184/hw3/cow_fast.png" width="100%" height="auto" alt="Cow Scene with BVH" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption">Cow Scene Rendering with BVH</div> </div> </div> <p>Building Scene:</p> <div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>❯ ./pathtracer <span class="nt">-t</span> 8 ../dae/keenan/building.dae
<span class="o">[</span>PathTracer] Input scene file: ../dae/keenan/building.dae
<span class="o">[</span>PathTracer] Rendering using 8 threads
<span class="o">[</span>PathTracer] Collecting primitives... Done! <span class="o">(</span>0.0018 sec<span class="o">)</span>
<span class="o">[</span>PathTracer] Building BVH from 39506 primitives... BVH Depth: 21
Done! <span class="o">(</span>0.0204 sec<span class="o">)</span>
<span class="o">[</span>PathTracer] Rendering... 100%! <span class="o">(</span>0.1948s<span class="o">)</span>
<span class="o">[</span>PathTracer] BVH traced 696438 rays.
<span class="o">[</span>PathTracer] Average speed 3.5746 million rays per second.
<span class="o">[</span>PathTracer] Averaged 7.951282 intersection tests per ray.
<span class="o">[</span>PathTracer] Rendering... 100%! <span class="o">(</span>0.1962s<span class="o">)</span>
<span class="o">[</span>PathTracer] BVH traced 715852 rays.
<span class="o">[</span>PathTracer] Average speed 3.6486 million rays per second.
<span class="o">[</span>PathTracer] Averaged 7.963509 intersection tests per ray.
</code></pre></div></div> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs184/hw3/part2_building-480.webp 480w,/assets/img/cs184/hw3/part2_building-800.webp 800w,/assets/img/cs184/hw3/part2_building-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/cs184/hw3/part2_building.png" width="100%" height="auto" alt="Building Scene with BVH" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption">Building Scene Rendering with BVH</div> </div> </div> <p>Lucy Scene:</p> <div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>❯ ./pathtracer <span class="nt">-t</span> 8 ../dae/sky/CBlucy.dae
<span class="o">[</span>PathTracer] Input scene file: ../dae/sky/CBlucy.dae
<span class="o">[</span>PathTracer] Rendering using 8 threads
<span class="o">[</span>PathTracer] Collecting primitives... Done! <span class="o">(</span>0.0074 sec<span class="o">)</span>
<span class="o">[</span>PathTracer] Building BVH from 133796 primitives... BVH Depth: 24
Done! <span class="o">(</span>0.0862 sec<span class="o">)</span>
<span class="o">[</span>PathTracer] Rendering... 100%! <span class="o">(</span>0.2072s<span class="o">)</span>
<span class="o">[</span>PathTracer] BVH traced 765431 rays.
<span class="o">[</span>PathTracer] Average speed 3.6949 million rays per second.
<span class="o">[</span>PathTracer] Averaged 3.609203 intersection tests per ray.
<span class="o">[</span>PathTracer] Rendering... 100%! <span class="o">(</span>0.2113s<span class="o">)</span>
<span class="o">[</span>PathTracer] BVH traced 893601 rays.
<span class="o">[</span>PathTracer] Average speed 4.2295 million rays per second.
<span class="o">[</span>PathTracer] Averaged 3.569567 intersection tests per ray.
<span class="o">[</span>PathTracer] Saving to file: CBlucy_screenshot_3-18_3-55-31.png... Done!
</code></pre></div></div> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs184/hw3/lucy_bvh-480.webp 480w,/assets/img/cs184/hw3/lucy_bvh-800.webp 800w,/assets/img/cs184/hw3/lucy_bvh-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/cs184/hw3/lucy_bvh.png" width="100%" height="auto" alt="Lucy Scene with BVH" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption">Lucy Scene visualization with BVH</div> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs184/hw3/part2_lucy-480.webp 480w,/assets/img/cs184/hw3/part2_lucy-800.webp 800w,/assets/img/cs184/hw3/part2_lucy-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/cs184/hw3/part2_lucy.png" width="100%" height="auto" alt="Lucy Scene with BVH" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption">Lucy Scene Rendering with BVH</div> </div> </div> <p>Our cow scene went from 5.6 seconds to 0.0388 seconds, for an improvement of 144x. Our building scene went from 161.1159 seconds to 0.1948 seconds, for an improvement of 827x. It is clear that BVH acceleration makes a significant difference in rendering time for scenes with a large number of primitives, and we can see the average intersection tests per ray is significantly lower with BVH acceleration, decreasing by a factor of over 1000x in some cases. The time increase in building the BVH is clearly worth the time saved in rendering.</p> <h2 id="direct-illumination">Direct Illumination</h2> <p>In our path tracer, we want to simulate the interaction of light with the scene, so we will need to get rid of our current implementation which uses the normal vector as a stand-in for the surface color. We will start by implementing direct illumination, which is the process of simulating the light that directly hits a surface. This involves calculating the light that comes from the light sources in the scene and hits the surface directly, without any bounces.</p> <h3 id="task-1-2">Task 1</h3> <p>We will start by updating our BSDF (Bidirectional Scattering Distribution Function) class to handle the reflection of light on diffuse surfaces. Our function <code class="language-plaintext highlighter-rouge">DiffuseBSDF::f</code> takes in <code class="language-plaintext highlighter-rouge">wo</code> and <code class="language-plaintext highlighter-rouge">wi</code> as the outgoing and incoming directions of the light in the object space, and returns the color of the light that is reflected in the direction <code class="language-plaintext highlighter-rouge">wi</code>. Because we are simulating a diffuse surface, the incoming and outgoing directions and point of intersection have no effect on the reflected light, so we can simply normalize the albedo of the surface by dividing by \(\pi\).</p> <h3 id="task-2-2">Task 2</h3> <p>Next, we will begin to implement our zero-bounce illumination by modifying <code class="language-plaintext highlighter-rouge">PathTracer::zero_bounce_radiance</code> to have the rays return the emmission of their first intersection. This will visualize where the light is coming from in the scene, but will not account for any bounces of light.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs184/hw3/part3_zerobounce-480.webp 480w,/assets/img/cs184/hw3/part3_zerobounce-800.webp 800w,/assets/img/cs184/hw3/part3_zerobounce-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/cs184/hw3/part3_zerobounce.png" width="100%" height="auto" alt="Zero Bounce Radiance" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption">Zero Bounce Radiance</div> </div> </div> <h3 id="task-3-2">Task 3</h3> <p>Next we will our one-bounce lighting, starting with Uniform Hemisphere Sampling which is a method of sampling the hemisphere around a intersection point. This is useful for simulating the reflection of light on a surface, as it allows us to sample the directions that light can come from in a way that is unbiased. We will modify <code class="language-plaintext highlighter-rouge">PathTracer::estimate_direct_lighting_hemisphere</code> to use this sampling method to estimate the direct lighting at a point. The algorithm involves using a Monte Carlo estimator to sample the hemisphere around the point and calculate the average light that comes from the light sources in the scene. This will give us a more accurate estimate of the direct lighting at the point, however it requires a large amount of samples to converge to the correct value. We can visualize the difference between the two methods by comparing the noise levels in the soft shadows of a scene with an area light source.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs184/hw3/part3_uniform_hemisphere_s16-480.webp 480w,/assets/img/cs184/hw3/part3_uniform_hemisphere_s16-800.webp 800w,/assets/img/cs184/hw3/part3_uniform_hemisphere_s16-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/cs184/hw3/part3_uniform_hemisphere_s16.png" width="100%" height="auto" alt="Uniform Hemisphere Sampling with 16 Samples" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption">Uniform Hemisphere Sampling with 16 Samples</div> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs184/hw3/part3_uniform_hemisphere_s64-480.webp 480w,/assets/img/cs184/hw3/part3_uniform_hemisphere_s64-800.webp 800w,/assets/img/cs184/hw3/part3_uniform_hemisphere_s64-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/cs184/hw3/part3_uniform_hemisphere_s64.png" width="100%" height="auto" alt="Uniform Hemisphere Sampling with 64 Samples" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption">Uniform Hemisphere Sampling with 64 Samples</div> </div> </div> <h3 id="task-4-1">Task 4</h3> <p>However we can be smarter about where we sample, after all we know that in our first bounce, the light must come from the light sources in the scene. Therefore we can modify <code class="language-plaintext highlighter-rouge">PathTracer::estimate_direct_lighting_importance</code> to instead sample from the points of intersection towards each of the light sources in the scene. If the ray intersects with an object on the way to the light source, we can ignore the light source as it is occluded. Otherwise, given we account for the range slightly above the surface and before the lightsource, a lack of a ray intersection between the two points means the lightsource is visible. If we have a point light source, we need to only sample it once, however if we have an area light source, we need to sample it multiple times to account for the area of the light source. By summing the light from each of the light sources, we can estimate the lighting reflected to the camera at that point. With this, we can achieve a more accurate estimate of the direct lighting at a point because we aren’t metaphorically/actually shooting in the dark in the hopes of hitting a light source.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs184/hw3/part3_importance_sampling_s64_l4-480.webp 480w,/assets/img/cs184/hw3/part3_importance_sampling_s64_l4-800.webp 800w,/assets/img/cs184/hw3/part3_importance_sampling_s64_l4-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/cs184/hw3/part3_importance_sampling_s64_l4.png" width="100%" height="auto" alt="Importance Sampling with 64 Samples and 4 Source Light Rays" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption">Importance Sampling with 64 Samples and 4 Source Light Rays</div> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs184/hw3/part3_dragon_s64_l32-480.webp 480w,/assets/img/cs184/hw3/part3_dragon_s64_l32-800.webp 800w,/assets/img/cs184/hw3/part3_dragon_s64_l32-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/cs184/hw3/part3_dragon_s64_l32.png" width="100%" height="auto" alt="Dragon Scene with 64 Samples and 32 Source Light Rays" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption">Dragon Scene with 64 Samples and 32 Source Light Rays</div> </div> </div> <h3 id="results-2">Results</h3> <p>Let us take a look at what happens when we increase the number of source light rays in our importance sampling, while holding the number of samples per ray constant.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs184/hw3/part3_importance_sampling_s1_l1-480.webp 480w,/assets/img/cs184/hw3/part3_importance_sampling_s1_l1-800.webp 800w,/assets/img/cs184/hw3/part3_importance_sampling_s1_l1-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/cs184/hw3/part3_importance_sampling_s1_l1.png" width="100%" height="auto" alt="Importance Sampling with 1 Source Light Ray" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption">Importance Sampling with 1 Source Light Ray</div> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs184/hw3/part3_importance_sampling_s1_l4-480.webp 480w,/assets/img/cs184/hw3/part3_importance_sampling_s1_l4-800.webp 800w,/assets/img/cs184/hw3/part3_importance_sampling_s1_l4-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/cs184/hw3/part3_importance_sampling_s1_l4.png" width="100%" height="auto" alt="Importance Sampling with 4 Source Light Rays" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption">Importance Sampling with 4 Source Light Rays</div> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs184/hw3/part3_importance_sampling_s1_l16-480.webp 480w,/assets/img/cs184/hw3/part3_importance_sampling_s1_l16-800.webp 800w,/assets/img/cs184/hw3/part3_importance_sampling_s1_l16-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/cs184/hw3/part3_importance_sampling_s1_l16.png" width="100%" height="auto" alt="Importance Sampling with 16 Source Light Rays" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption">Importance Sampling with 16 Source Light Rays</div> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs184/hw3/part3_importance_sampling_s1_l64-480.webp 480w,/assets/img/cs184/hw3/part3_importance_sampling_s1_l64-800.webp 800w,/assets/img/cs184/hw3/part3_importance_sampling_s1_l64-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/cs184/hw3/part3_importance_sampling_s1_l64.png" width="100%" height="auto" alt="Importance Sampling with 64 Source Light Rays" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption">Importance Sampling with 64 Source Light Rays</div> </div> </div> <p>As we increase the number of samples for each source light ray in our importance sampling, we can see the shadows becoming softer, this is because more of them are being sampled, and instead of having a very poor estimate of the light, the Monte Carlo estimator is able to converge to the correct value. This is why we see the noise levels decrease as we increase the number of samples. However, so does the time it takes to render the image, as we are sampling more rays for each light source.</p> <div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>❯ ./pathtracer <span class="nt">-t</span> 8 <span class="nt">-s</span> 1 <span class="nt">-l</span> 1 <span class="nt">-m</span> 6 <span class="nt">-f</span> part3_importance_sampling_s1_l1.png <span class="nt">-r</span> 480 360 ../dae/sky/CBbunny.dae
...
<span class="o">[</span>PathTracer] Rendering... 100%! <span class="o">(</span>0.0411s<span class="o">)</span>
...
❯ ./pathtracer <span class="nt">-t</span> 8 <span class="nt">-s</span> 1 <span class="nt">-l</span> 4 <span class="nt">-m</span> 6 <span class="nt">-f</span> part3_importance_sampling_s1_l4.png <span class="nt">-r</span> 480 360 ../dae/sky/CBbunny.dae
...
<span class="o">[</span>PathTracer] Rendering... 100%! <span class="o">(</span>0.1143s<span class="o">)</span>
...
❯ ./pathtracer <span class="nt">-t</span> 8 <span class="nt">-s</span> 1 <span class="nt">-l</span> 16 <span class="nt">-m</span> 6 <span class="nt">-f</span> part3_importance_sampling_s1_l16.png <span class="nt">-r</span> 480 360 ../dae/sky/CBbunny.dae
...
<span class="o">[</span>PathTracer] Rendering... 100%! <span class="o">(</span>0.3653s<span class="o">)</span>
...
❯ ./pathtracer <span class="nt">-t</span> 8 <span class="nt">-s</span> 1 <span class="nt">-l</span> 64 <span class="nt">-m</span> 6 <span class="nt">-f</span> part3_importance_sampling_s1_l64.png <span class="nt">-r</span> 480 360 ../dae/sky/CBbunny.dae
...
<span class="o">[</span>PathTracer] Rendering... 100%! <span class="o">(</span>1.0336s<span class="o">)</span>
...
</code></pre></div></div> <div class="container l-page"> <div class="row text-center fw-bold"> <div class="col-sm"># Samples per Pixel / Samples per Source Light</div> <div class="col">Uniform Hemisphere Sampling</div> <div class="col">Importance Sampling</div> </div> <div class="row align-items-center text-center"> <div class="col-auto">8 / 4</div> <div class="col"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs184/hw3/part3_bunny_uniform_s8_l4-480.webp 480w,/assets/img/cs184/hw3/part3_bunny_uniform_s8_l4-800.webp 800w,/assets/img/cs184/hw3/part3_bunny_uniform_s8_l4-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/cs184/hw3/part3_bunny_uniform_s8_l4.png" width="100%" height="auto" alt="Uniform Hemisphere Sampling with 8 Samples and 4 Source Light Rays" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption">0.6797s</div> </div> <div class="col"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs184/hw3/part3_bunny_importance_s8_l4-480.webp 480w,/assets/img/cs184/hw3/part3_bunny_importance_s8_l4-800.webp 800w,/assets/img/cs184/hw3/part3_bunny_importance_s8_l4-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/cs184/hw3/part3_bunny_importance_s8_l4.png" width="100%" height="auto" alt="Importance Sampling with 8 Samples and 4 Source Light Rays" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption">0.7308s</div> </div> </div> <div class="row align-items-center text-center"> <div class="col-auto">16 / 8</div> <div class="col"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs184/hw3/part3_bunny_uniform_s16_l8-480.webp 480w,/assets/img/cs184/hw3/part3_bunny_uniform_s16_l8-800.webp 800w,/assets/img/cs184/hw3/part3_bunny_uniform_s16_l8-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/cs184/hw3/part3_bunny_uniform_s16_l8.png" width="100%" height="auto" alt="Uniform Hemisphere Sampling with 16 Samples and 8 Source Light Rays" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption">3.3095s</div> </div> <div class="col"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs184/hw3/part3_bunny_importance_s16_l8-480.webp 480w,/assets/img/cs184/hw3/part3_bunny_importance_s16_l8-800.webp 800w,/assets/img/cs184/hw3/part3_bunny_importance_s16_l8-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/cs184/hw3/part3_bunny_importance_s16_l8.png" width="100%" height="auto" alt="Importance Sampling with 16 Samples and 8 Source Light Rays" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption">2.6805s</div> </div> </div> <div class="row align-items-center text-center"> <div class="col-auto">32 / 16</div> <div class="col"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs184/hw3/part3_bunny_uniform_s32_l16-480.webp 480w,/assets/img/cs184/hw3/part3_bunny_uniform_s32_l16-800.webp 800w,/assets/img/cs184/hw3/part3_bunny_uniform_s32_l16-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/cs184/hw3/part3_bunny_uniform_s32_l16.png" width="100%" height="auto" alt="Uniform Hemisphere Sampling with 32 Samples and 16 Source Light Rays" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption">13.7694s</div> </div> <div class="col"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs184/hw3/part3_bunny_importance_s32_l16-480.webp 480w,/assets/img/cs184/hw3/part3_bunny_importance_s32_l16-800.webp 800w,/assets/img/cs184/hw3/part3_bunny_importance_s32_l16-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/cs184/hw3/part3_bunny_importance_s32_l16.png" width="100%" height="auto" alt="Importance Sampling with 32 Samples and 16 Source Light Rays" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption">9.8483s</div> </div> </div> <div class="row align-items-center text-center"> <div class="col-auto">64 / 32</div> <div class="col"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs184/hw3/part3_bunny_uniform_s64_l32-480.webp 480w,/assets/img/cs184/hw3/part3_bunny_uniform_s64_l32-800.webp 800w,/assets/img/cs184/hw3/part3_bunny_uniform_s64_l32-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/cs184/hw3/part3_bunny_uniform_s64_l32.png" width="100%" height="auto" alt="Uniform Hemisphere Sampling with 64 Samples and 32 Source Light Rays" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption">60.0449s</div> </div> <div class="col"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs184/hw3/part3_bunny_importance_s64_l32-480.webp 480w,/assets/img/cs184/hw3/part3_bunny_importance_s64_l32-800.webp 800w,/assets/img/cs184/hw3/part3_bunny_importance_s64_l32-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/cs184/hw3/part3_bunny_importance_s64_l32.png" width="100%" height="auto" alt="Importance Sampling with 64 Samples and 32 Source Light Rays" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption">46.6251s</div> </div> </div> <div class="row align-items-center text-center"> <div class="col-auto">128 / 64</div> <div class="col"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs184/hw3/part3_bunny_uniform_s128_l64-480.webp 480w,/assets/img/cs184/hw3/part3_bunny_uniform_s128_l64-800.webp 800w,/assets/img/cs184/hw3/part3_bunny_uniform_s128_l64-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/cs184/hw3/part3_bunny_uniform_s128_l64.png" width="100%" height="auto" alt="Uniform Hemisphere Sampling with 128 Samples and 64 Source Light Rays" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption">231.3099s</div> </div> <div class="col"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs184/hw3/part3_bunny_importance_s128_l64-480.webp 480w,/assets/img/cs184/hw3/part3_bunny_importance_s128_l64-800.webp 800w,/assets/img/cs184/hw3/part3_bunny_importance_s128_l64-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/cs184/hw3/part3_bunny_importance_s128_l64.png" width="100%" height="auto" alt="Importance Sampling with 128 Samples and 64 Source Light Rays" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption">175.9478s</div> </div> </div> </div> <p>As we can compare, importance sampling is able to achieve a much better estimate of the direct lighting at a point than uniform hemisphere sampling for the same number of samples. This is because importance sampling is able to sample the areas on the hemisphere that are possible to contribute to the lighting in one bounce, while uniform hemisphere sampling’s random sampling can miss these possibly small areas in soft shadows. We can that the noise level is lower in the importance sampling images, and the shadows are softer, which is a sign that the Monte Carlo estimator is converging to the correct value. Additionally, there are time savings because we can discard rays that intersect with objects on the way to the light source, which is not possible with uniform hemisphere sampling as we need to always find the closest intersection point. After writing this section, I was able to go back to my importance sampling implementation and use the has_intersection function of the BVH to check if the ray intersects with an object on the way to the light source, which is a much more efficient way of checking if the light source is visible rather than getting the closest intersection point.</p> <h2 id="global-illumination">Global Illumination</h2> <p>With our current implementation, we are only able to simulate the direct lighting in the scene, which is the light that comes from the light sources and hits the surface directly, or the light that is reflected off the surface in one bounce. However, we want to simulate the indirect lighting in the scene, which is the light that comes from the light sources, bounces off multiple surfaces, and eventually hits the surface. This is important because it is the light that gives the scene its color and makes it look realistic.</p> <h3 id="task-1-3">Task 1</h3> <p>We will re-examine our function <code class="language-plaintext highlighter-rouge">sample_f</code> in our BSDF class, which is used to sample an incoming direction <code class="language-plaintext highlighter-rouge">wi</code> given an outgoing direction <code class="language-plaintext highlighter-rouge">wo</code> using a cosine-weighted hemisphere. We store the pdf of the direction in <code class="language-plaintext highlighter-rouge">pdf</code>, which is the probability of sampling the direction <code class="language-plaintext highlighter-rouge">wi</code> given the direction <code class="language-plaintext highlighter-rouge">wo</code>, and return the reflectance of the surface by using <code class="language-plaintext highlighter-rouge">DiffuseBSDF::f</code>. This is be important for our next task, in which we will want to sample outgoing rays from our hit points.</p> <h3 id="task-2-3">Task 2</h3> <p>In this section, we complete the function <code class="language-plaintext highlighter-rouge">PathTracer::at_least_one_bounce_radiance</code>, which will help us simulate the indirect lighting in the scene. We begin by modifying the initialization of our rays to have a depth of <code class="language-plaintext highlighter-rouge">max_ray_depth</code>, which is the maximum number of bounces we want to simulate. Our algorithmic logic is as follows:</p> <ol> <li>If our ray has reached the maximum depth i.e. <code class="language-plaintext highlighter-rouge">max_ray_depth</code> is 0, we return the one-bounce radiance at the hit point.</li> <li>Else, we sample the incoming direction <code class="language-plaintext highlighter-rouge">wi</code> using the BSDF at the hit point.</li> <li>If this ray intersects with an object in the scene, we recursively call <code class="language-plaintext highlighter-rouge">at_least_one_bounce_radiance</code> with the new ray and decrement the depth.</li> <li>If isAccumBounces is true, we accumulate the radiance from one-bounce at our hit point with the radiance from the recursive call.</li> <li>We return the radiance at the hit point.</li> </ol> <h3 id="task-3-3">Task 3</h3> <p>We will now modify our function <code class="language-plaintext highlighter-rouge">PathTracer::at_least_one_bounce_radiance</code> to simulate the integration over all possible path lengths in the scene. We will accomplish this by applying a Russian Roulette technique, which is a method of randomly terminating rays before they have reached the maximum depth. This is done by using a probability of termination, which I have set to 0.35. This will allow us to increase the maximum depth of our rays without increasing the render time significantly, as rays have 35% chance of being terminated at each bounce. In fact, at a depth of 16, a ray only has a 0.1 % chance of reaching the maximum depth.</p> <h3 id="results-3">Results</h3> <p>Lets take a look at the results of our global illumination implementation vs. their direct illumination counterparts.</p> <div class="container l-page"> <div class="row text-center fw-bold"> <div class="col-sm">Direct Illumination</div> <div class="col">Indirect Illumination</div> </div> <div class="row align-items-center text-center"> <div class="col"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs184/hw3/part4_bunny_direct-480.webp 480w,/assets/img/cs184/hw3/part4_bunny_direct-800.webp 800w,/assets/img/cs184/hw3/part4_bunny_direct-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/cs184/hw3/part4_bunny_direct.png" width="100%" height="auto" alt="Direct Illumination of Bunny Scene" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs184/hw3/part4_bunny_indirect-480.webp 480w,/assets/img/cs184/hw3/part4_bunny_indirect-800.webp 800w,/assets/img/cs184/hw3/part4_bunny_indirect-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/cs184/hw3/part4_bunny_indirect.png" width="100%" height="auto" alt="Indirect Illumination of Bunny Scene" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="row align-items-center text-center"> <div class="col"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs184/hw3/part4_dragon_direct-480.webp 480w,/assets/img/cs184/hw3/part4_dragon_direct-800.webp 800w,/assets/img/cs184/hw3/part4_dragon_direct-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/cs184/hw3/part4_dragon_direct.png" width="100%" height="auto" alt="Direct Illumination of Dragon Scene" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs184/hw3/part4_dragon_indirect-480.webp 480w,/assets/img/cs184/hw3/part4_dragon_indirect-800.webp 800w,/assets/img/cs184/hw3/part4_dragon_indirect-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/cs184/hw3/part4_dragon_indirect.png" width="100%" height="auto" alt="Indirect Illumination of Dragon Scene" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="row align-items-center text-center"> <div class="col"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs184/hw3/part4_lucy_direct-480.webp 480w,/assets/img/cs184/hw3/part4_lucy_direct-800.webp 800w,/assets/img/cs184/hw3/part4_lucy_direct-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/cs184/hw3/part4_lucy_direct.png" width="100%" height="auto" alt="Direct Illumination of Lucy Scene" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs184/hw3/part4_lucy_indirect-480.webp 480w,/assets/img/cs184/hw3/part4_lucy_indirect-800.webp 800w,/assets/img/cs184/hw3/part4_lucy_indirect-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/cs184/hw3/part4_lucy_indirect.png" width="100%" height="auto" alt="Indirect Illumination of Lucy Scene" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="row align-items-center text-center"> <div class="col"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs184/hw3/part4_spheres_direct-480.webp 480w,/assets/img/cs184/hw3/part4_spheres_direct-800.webp 800w,/assets/img/cs184/hw3/part4_spheres_direct-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/cs184/hw3/part4_spheres_direct.png" width="100%" height="auto" alt="Direct Illumination of Spheres Scene" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs184/hw3/part4_spheres_indirect-480.webp 480w,/assets/img/cs184/hw3/part4_spheres_indirect-800.webp 800w,/assets/img/cs184/hw3/part4_spheres_indirect-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/cs184/hw3/part4_spheres_indirect.png" width="100%" height="auto" alt="Indirect Illumination of Spheres Scene" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> </div> <p>We can see that the indirect illumination images have a much more realistic look to them, as they are able to capture the color of the scene and the light that is reflected off the surfaces. This is because the indirect illumination is able to simulate the light that bounces off multiple surfaces and eventually hits the surface, which is what gives the scene its color. The direct illumination images are much more flat and do not capture the color of the scene, as they only simulate the light that comes from the light sources and hits the surface directly or is reflected off the surface in one bounce.</p> <p>However, not all scenes equally benefit from indirect lighting, let us take a look at a scene that is significantly more complex than the others, but doesn’t have the geometry that would benefit from indirect lighting.</p> <div class="container l-page"> <div class="row align-items-center text-center"> <div class="col"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs184/hw3/building_screenshot_3-20_2-30-15-480.webp 480w,/assets/img/cs184/hw3/building_screenshot_3-20_2-30-15-800.webp 800w,/assets/img/cs184/hw3/building_screenshot_3-20_2-30-15-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/cs184/hw3/building_screenshot_3-20_2-30-15.png" width="100%" height="auto" alt="Direct Illumination of Building Scene" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption">Direct Illumination</div> </div> <div class="col"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs184/hw3/building_screenshot_3-20_2-34-34-480.webp 480w,/assets/img/cs184/hw3/building_screenshot_3-20_2-34-34-800.webp 800w,/assets/img/cs184/hw3/building_screenshot_3-20_2-34-34-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/cs184/hw3/building_screenshot_3-20_2-34-34.png" width="100%" height="auto" alt="Indirect Illumination of Building Scene" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption">Indirect Illumination - Ray Depth 2</div> </div> <div class="col"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs184/hw3/building_screenshot_3-20_2-38-19-480.webp 480w,/assets/img/cs184/hw3/building_screenshot_3-20_2-38-19-800.webp 800w,/assets/img/cs184/hw3/building_screenshot_3-20_2-38-19-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/cs184/hw3/building_screenshot_3-20_2-38-19.png" width="100%" height="auto" alt="Indirect Illumination of Building Scene" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption">Indirect Illumination - Ray Depth 3</div> </div> </div> </div> <p>To understand the effect that indirect lighting has, let us see exactly what it is adding by removing the first bounce contribution in our indirect illumination image.</p> <div class="container l-page"> <div class="row text-center fw-bold"> <div class="col">Direct Illumination</div> <div class="col">&gt;1 Bounce Indirect Illumination</div> <div class="col">&gt;Indirect Illumination</div> </div> <div class="row align-items-center text-center"> <div class="col"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs184/hw3/part4_dragon_direct-480.webp 480w,/assets/img/cs184/hw3/part4_dragon_direct-800.webp 800w,/assets/img/cs184/hw3/part4_dragon_direct-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/cs184/hw3/part4_dragon_direct.png" width="100%" height="auto" alt="Direct Illumination of Dragon Scene" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs184/hw3/part4_dragon_indirect_nozero-480.webp 480w,/assets/img/cs184/hw3/part4_dragon_indirect_nozero-800.webp 800w,/assets/img/cs184/hw3/part4_dragon_indirect_nozero-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/cs184/hw3/part4_dragon_indirect_nozero.png" width="100%" height="auto" alt="Indirect Illumination of Dragon Scene without Zero Bounce" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs184/hw3/part4_dragon_indirect-480.webp 480w,/assets/img/cs184/hw3/part4_dragon_indirect-800.webp 800w,/assets/img/cs184/hw3/part4_dragon_indirect-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/cs184/hw3/part4_dragon_indirect.png" width="100%" height="auto" alt="Indirect Illumination of Dragon Scene" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> </div> <p>We can see that the indirect illumination image without our ray’s first intersection’s one-bounce contribution is much darker and has less color than the indirect illumination image with this contribution. This is because this first one-bounce calculation captures the light that comes from this surface directly from the light sources, which carries significant energy that is used in our scene coloring. You can also visualize how the two images on the left would combine to form the right image.</p> <p>Next, we will compare the quality of the rendered image with different numbers of bounces of light. We will render the mth bounce of light with max_ray_depth set to 0, 1, 2, 3, 4, and 5, and isAccumBounces=false. We will also compare the rendered views of accumulated and unaccumulated bounces for the bunny scene with max_ray_depth set to 0, 1, 2, 3, 4, and 5. We will remove our zero-bounce contribution from our non-accumulated bounces images to see just the effect of the bounces of light.</p> <div class="container l-page"> <div class="row text-center fw-bold"> <div class="col-sm">Unaccumulated Bounces</div> <div class="col">Accumulated Bounces</div> </div> <div class="row align-items-center text-center"> <div class="col-sm"> 0 Max Depth </div> <div class="col"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs184/hw3/part4_bunny_m0_noaccum-480.webp 480w,/assets/img/cs184/hw3/part4_bunny_m0_noaccum-800.webp 800w,/assets/img/cs184/hw3/part4_bunny_m0_noaccum-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/cs184/hw3/part4_bunny_m0_noaccum.png" width="100%" height="auto" alt="Unaccumulated Bounces of Bunny Scene with 0 Max Depth" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs184/hw3/part4_bunny_m0-480.webp 480w,/assets/img/cs184/hw3/part4_bunny_m0-800.webp 800w,/assets/img/cs184/hw3/part4_bunny_m0-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/cs184/hw3/part4_bunny_m0.png" width="100%" height="auto" alt="Accumulated Bounces of Bunny Scene with 0 Max Depth" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="row align-items-center text-center"> <div class="col-sm"> 1 Max Depth </div> <div class="col"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs184/hw3/part4_bunny_m1_noaccum-480.webp 480w,/assets/img/cs184/hw3/part4_bunny_m1_noaccum-800.webp 800w,/assets/img/cs184/hw3/part4_bunny_m1_noaccum-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/cs184/hw3/part4_bunny_m1_noaccum.png" width="100%" height="auto" alt="Unaccumulated Bounces of Bunny Scene with 1 Max Depth" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs184/hw3/part4_bunny_m1-480.webp 480w,/assets/img/cs184/hw3/part4_bunny_m1-800.webp 800w,/assets/img/cs184/hw3/part4_bunny_m1-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/cs184/hw3/part4_bunny_m1.png" width="100%" height="auto" alt="Accumulated Bounces of Bunny Scene with 1 Max Depth" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="row align-items-center text-center"> <div class="col-sm"> 2 Max Depth </div> <div class="col"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs184/hw3/part4_bunny_m2_noaccum-480.webp 480w,/assets/img/cs184/hw3/part4_bunny_m2_noaccum-800.webp 800w,/assets/img/cs184/hw3/part4_bunny_m2_noaccum-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/cs184/hw3/part4_bunny_m2_noaccum.png" width="100%" height="auto" alt="Unaccumulated Bounces of Bunny Scene with 2 Max Depth" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs184/hw3/part4_bunny_m2-480.webp 480w,/assets/img/cs184/hw3/part4_bunny_m2-800.webp 800w,/assets/img/cs184/hw3/part4_bunny_m2-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/cs184/hw3/part4_bunny_m2.png" width="100%" height="auto" alt="Accumulated Bounces of Bunny Scene with 2 Max Depth" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="row align-items-center text-center"> <div class="col-sm"> 3 Max Depth </div> <div class="col"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs184/hw3/part4_bunny_m3_noaccum-480.webp 480w,/assets/img/cs184/hw3/part4_bunny_m3_noaccum-800.webp 800w,/assets/img/cs184/hw3/part4_bunny_m3_noaccum-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/cs184/hw3/part4_bunny_m3_noaccum.png" width="100%" height="auto" alt="Unaccumulated Bounces of Bunny Scene with 3 Max Depth" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs184/hw3/part4_bunny_m3-480.webp 480w,/assets/img/cs184/hw3/part4_bunny_m3-800.webp 800w,/assets/img/cs184/hw3/part4_bunny_m3-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/cs184/hw3/part4_bunny_m3.png" width="100%" height="auto" alt="Accumulated Bounces of Bunny Scene with 3 Max Depth" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="row align-items-center text-center"> <div class="col-sm"> 4 Max Depth </div> <div class="col"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs184/hw3/part4_bunny_m4_noaccum-480.webp 480w,/assets/img/cs184/hw3/part4_bunny_m4_noaccum-800.webp 800w,/assets/img/cs184/hw3/part4_bunny_m4_noaccum-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/cs184/hw3/part4_bunny_m4_noaccum.png" width="100%" height="auto" alt="Unaccumulated Bounces of Bunny Scene with 4 Max Depth" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs184/hw3/part4_bunny_m4-480.webp 480w,/assets/img/cs184/hw3/part4_bunny_m4-800.webp 800w,/assets/img/cs184/hw3/part4_bunny_m4-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/cs184/hw3/part4_bunny_m4.png" width="100%" height="auto" alt="Accumulated Bounces of Bunny Scene with 4 Max Depth" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="row align-items-center text-center"> <div class="col-sm"> 5 Max Depth </div> <div class="col"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs184/hw3/part4_bunny_m5_noaccum-480.webp 480w,/assets/img/cs184/hw3/part4_bunny_m5_noaccum-800.webp 800w,/assets/img/cs184/hw3/part4_bunny_m5_noaccum-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/cs184/hw3/part4_bunny_m5_noaccum.png" width="100%" height="auto" alt="Unaccumulated Bounces of Bunny Scene with 5 Max Depth" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs184/hw3/part4_bunny_m5-480.webp 480w,/assets/img/cs184/hw3/part4_bunny_m5-800.webp 800w,/assets/img/cs184/hw3/part4_bunny_m5-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/cs184/hw3/part4_bunny_m5.png" width="100%" height="auto" alt="Accumulated Bounces of Bunny Scene with 5 Max Depth" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> </div> <p>We can see that the accumulated bounces images gain brightness and color all around, but most noticeable in the shadows in our early increases. This is because the accumulated bounces are able to capture the light that bounces off multiple surfaces and eventually hits the surface. The brightness of each incremental bounce is less than the previous one, however we can see distinct information in each bounce, such as the 2nd bounce containing information to the bottom areas of the bunny, which is being generated from bounces that have gone off the floor and then reached the light. This is contrasted to the third bounce, which lacks this shadow information, but upon inspection contains more information around the creases of the bunny, which is being generated from bounces that have escaped crevices and then reached the light. This is a significant improvement over our direct illumination images, which are much flatter and this expected behavior of light.</p> <p>Now we can compare the effect of Russian Roulette on the quality of the rendered image. We will output the Russian Roulette rendering with max_ray_depth set to 0, 1, 2, 3, 4, and 100. Normally, 100 bounces would be computationally expensive, but because of Russian Roulette, we can still get a good estimate of the image with a much lower number of bounces.</p> <div class="container l-page"> <div class="row align-items-center text-center"> <div class="col"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs184/hw3/part4_bunny_m0_rr-480.webp 480w,/assets/img/cs184/hw3/part4_bunny_m0_rr-800.webp 800w,/assets/img/cs184/hw3/part4_bunny_m0_rr-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/cs184/hw3/part4_bunny_m0_rr.png" width="100%" height="auto" alt="Russian Roulette of Bunny Scene with 0 Max Depth" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption">0 Max Depth</div> </div> <div class="col"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs184/hw3/part4_bunny_m1_rr-480.webp 480w,/assets/img/cs184/hw3/part4_bunny_m1_rr-800.webp 800w,/assets/img/cs184/hw3/part4_bunny_m1_rr-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/cs184/hw3/part4_bunny_m1_rr.png" width="100%" height="auto" alt="Russian Roulette of Bunny Scene with 1 Max Depth" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption">1 Max Depth</div> </div> <div class="col"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs184/hw3/part4_bunny_m2_rr-480.webp 480w,/assets/img/cs184/hw3/part4_bunny_m2_rr-800.webp 800w,/assets/img/cs184/hw3/part4_bunny_m2_rr-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/cs184/hw3/part4_bunny_m2_rr.png" width="100%" height="auto" alt="Russian Roulette of Bunny Scene with 2 Max Depth" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption">2 Max Depth</div> </div> </div> <div class="row align-items-center text-center"> <div class="col"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs184/hw3/part4_bunny_m3_rr-480.webp 480w,/assets/img/cs184/hw3/part4_bunny_m3_rr-800.webp 800w,/assets/img/cs184/hw3/part4_bunny_m3_rr-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/cs184/hw3/part4_bunny_m3_rr.png" width="100%" height="auto" alt="Russian Roulette of Bunny Scene with 3 Max Depth" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption">3 Max Depth</div> </div> <div class="col"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs184/hw3/part4_bunny_m4_rr-480.webp 480w,/assets/img/cs184/hw3/part4_bunny_m4_rr-800.webp 800w,/assets/img/cs184/hw3/part4_bunny_m4_rr-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/cs184/hw3/part4_bunny_m4_rr.png" width="100%" height="auto" alt="Russian Roulette of Bunny Scene with 4 Max Depth" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption">4 Max Depth</div> </div> <div class="col"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs184/hw3/part4_bunny_m100_rr-480.webp 480w,/assets/img/cs184/hw3/part4_bunny_m100_rr-800.webp 800w,/assets/img/cs184/hw3/part4_bunny_m100_rr-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/cs184/hw3/part4_bunny_m100_rr.png" width="100%" height="auto" alt="Russian Roulette of Bunny Scene with 100 Max Depth" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption">100 Max Depth</div> </div> </div> </div> <p>We can see that the Russian Roulette from 1 to 4 bounces offers a significant improvement in the quality of the image, as we have a larger range of path lengths we sample from. However, the Russian Roulette with 100 bounces does not offer a significant improvement in the quality of the image, as we do not even likely reach the maximum depth of 100 bounces. This is because the probability of a ray reaching depth \(d\) is \((1 - p*{term})^d\), where \(p*{term}\) is the probability of termination, which is 0.35 in our case. This means that the probability of a ray reaching depth 100 is \(1.95585054 \times 10^{-19}\), which is very low.</p> <p>Finally, we will compare the effect of the number of samples per pixel on the quality of the rendered image. We will render the dragon scene with 4 light rays and compare the rendered views with various sample-per-pixel rates: 1, 2, 4, 8, 16, 64, 256, and 1024.</p> <div class="container l-page"> <div class="row align-items-center text-center"> <div class="col"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs184/hw3/part4_dragon_s1_l4-480.webp 480w,/assets/img/cs184/hw3/part4_dragon_s1_l4-800.webp 800w,/assets/img/cs184/hw3/part4_dragon_s1_l4-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/cs184/hw3/part4_dragon_s1_l4.png" width="100%" height="auto" alt="Dragon Scene with 1 Sample per Pixel" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption">1 Sample per Pixel</div> </div> <div class="col"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs184/hw3/part4_dragon_s2_l4-480.webp 480w,/assets/img/cs184/hw3/part4_dragon_s2_l4-800.webp 800w,/assets/img/cs184/hw3/part4_dragon_s2_l4-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/cs184/hw3/part4_dragon_s2_l4.png" width="100%" height="auto" alt="Dragon Scene with 2 Samples per Pixel" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption">2 Samples per Pixel</div> </div> <div class="col"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs184/hw3/part4_dragon_s4_l4-480.webp 480w,/assets/img/cs184/hw3/part4_dragon_s4_l4-800.webp 800w,/assets/img/cs184/hw3/part4_dragon_s4_l4-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/cs184/hw3/part4_dragon_s4_l4.png" width="100%" height="auto" alt="Dragon Scene with 4 Samples per Pixel" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption">4 Samples per Pixel</div> </div> </div> <div class="row align-items-center text-center"> <div class="col"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs184/hw3/part4_dragon_s8_l4-480.webp 480w,/assets/img/cs184/hw3/part4_dragon_s8_l4-800.webp 800w,/assets/img/cs184/hw3/part4_dragon_s8_l4-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/cs184/hw3/part4_dragon_s8_l4.png" width="100%" height="auto" alt="Dragon Scene with 8 Samples per Pixel" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption">8 Samples per Pixel</div> </div> <div class="col"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs184/hw3/part4_dragon_s16_l4-480.webp 480w,/assets/img/cs184/hw3/part4_dragon_s16_l4-800.webp 800w,/assets/img/cs184/hw3/part4_dragon_s16_l4-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/cs184/hw3/part4_dragon_s16_l4.png" width="100%" height="auto" alt="Dragon Scene with 16 Samples per Pixel" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption">16 Samples per Pixel</div> </div> <div class="col"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs184/hw3/part4_dragon_s64_l4-480.webp 480w,/assets/img/cs184/hw3/part4_dragon_s64_l4-800.webp 800w,/assets/img/cs184/hw3/part4_dragon_s64_l4-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/cs184/hw3/part4_dragon_s64_l4.png" width="100%" height="auto" alt="Dragon Scene with 64 Samples per Pixel" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption">64 Samples per Pixel</div> </div> </div> <div class="row align-items-center text-center"> <div class="col"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs184/hw3/part4_dragon_s256_l4-480.webp 480w,/assets/img/cs184/hw3/part4_dragon_s256_l4-800.webp 800w,/assets/img/cs184/hw3/part4_dragon_s256_l4-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/cs184/hw3/part4_dragon_s256_l4.png" width="100%" height="auto" alt="Dragon Scene with 256 Samples per Pixel" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption">256 Samples per Pixel</div> </div> <div class="col"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs184/hw3/part4_dragon_s1024_l4-480.webp 480w,/assets/img/cs184/hw3/part4_dragon_s1024_l4-800.webp 800w,/assets/img/cs184/hw3/part4_dragon_s1024_l4-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/cs184/hw3/part4_dragon_s1024_l4.png" width="100%" height="auto" alt="Dragon Scene with 1024 Samples per Pixel" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption">1024 Samples per Pixel</div> </div> </div> </div> <p>We can see that the quality of the rendered image improves as we increase the number of samples per pixel. This is because the more samples we take per pixel, the more accurate our estimate of the radiance at that pixel will be. This is because in our Monte Carlo estimation, we need many samples to be able to obtain a good average, which will give us a more accurate estimate of the radiance at that pixel. We can see that the images with 1 and 2 samples per pixel have a lot of noise in them, while the images with 1024 samples per pixel are much cleaner and have less noise.</p> <h2 id="adaptive-sampling">Adaptive Sampling</h2> <p>It is quite computationally expensive to have 1024 samples across the entire scene, as certain parts of the scene may not need that many samples to get a good estimate of the radiance at that pixel, while other parts of the scene will definitely require the full 1024 samples. This is where adaptive sampling comes in, with it we can take more samples in the areas of the scene that need it and fewer samples in the areas of the scene that do not need it. This will allow us to get a good estimate of the radiance at each pixel in the scene while reducing the number of samples we need to take.</p> <h3 id="task-1-4">Task 1</h3> <p>We will go back to our <code class="language-plaintext highlighter-rouge">PathTracer::raytrace_pixel</code> function to implement adaptive sampling. We will begin by initializing variables to keep track of the current number of ray samples per pixel, the sum of illuminance received from every ray sample, and the sum of the illuminance squared received from every ray sample. As we loop through the number of samples per pixel, as before, we will calculate the radiance at the pixel for each sample and add it’s contribution onto a running sum. Then for each ray sample, we will add to our two running luminance sums, and when we have reached our batch size, we will calculate the mean, \(\mu\), and the variance, \(\sigma^2\), of the luminance samples. We will then calculate the confidence interval, \(I\), of the luminance samples, which is given by \(I = 1.96 \times \frac{\sigma}{\sqrt{N}}\), where $ N $ is the number of samples. If the confidence interval is less than \({tol} \times \mu\), we will break out of the loop and return the mean of the radiance sum. If the confidence interval is greater than \({tol} \times \mu\), we will continue to take samples until we reach the maximum number of samples per pixel.</p> <h3 id="results-4">Results</h3> <p>I first tested out adaptive sampling on the bunny scene with 2048 samples per pixel, 1 light ray, a maximum depth of 5, with a batch size of 64 and a tolerance of 0.05. This took 108.3176s to render!</p> <div class="container l-page"> <div class="row align-items-center text-center"> <div class="col"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs184/hw3/bunny_adaptive-480.webp 480w,/assets/img/cs184/hw3/bunny_adaptive-800.webp 800w,/assets/img/cs184/hw3/bunny_adaptive-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/cs184/hw3/bunny_adaptive.png" width="100%" height="auto" alt="Adaptive Sampling of Bunny Scene" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption">Adaptive Sampling</div> </div> <div class="col"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs184/hw3/bunny_rate_adaptive-480.webp 480w,/assets/img/cs184/hw3/bunny_rate_adaptive-800.webp 800w,/assets/img/cs184/hw3/bunny_rate_adaptive-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/cs184/hw3/bunny_rate_adaptive.png" width="100%" height="auto" alt="Adaptive Sampling Rate of Bunny Scene" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption">Adaptive Sampling Rate</div> </div> </div> </div> <p>I additionally tested out adaptive sampling on the dragon scene with the same parameters as the bunny scene, which took 221.1808s to render. (There were other large renders running concurrently, so this time is not indicative of the actual time it would take to render the scene.)</p> <div class="container l-page"> <div class="row align-items-center text-center"> <div class="col"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs184/hw3/dragon_adaptive-480.webp 480w,/assets/img/cs184/hw3/dragon_adaptive-800.webp 800w,/assets/img/cs184/hw3/dragon_adaptive-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/cs184/hw3/dragon_adaptive.png" width="100%" height="auto" alt="Adaptive Sampling of Dragon Scene" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption">Adaptive Sampling</div> </div> <div class="col"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs184/hw3/dragon_adaptive_rate-480.webp 480w,/assets/img/cs184/hw3/dragon_adaptive_rate-800.webp 800w,/assets/img/cs184/hw3/dragon_adaptive_rate-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/cs184/hw3/dragon_adaptive_rate.png" width="100%" height="auto" alt="Adaptive Sampling Rate of Dragon Scene" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption">Adaptive Sampling Rate</div> </div> </div> </div> <p>I decided to go for two large 1080x1080 renders to see all the implemented features in action.</p> <div class="container l-page"> <div class="row align-items-center text-center"> <div class="col"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs184/hw3/CBbunny_screenshot_3-20_5-2-12_rate-480.webp 480w,/assets/img/cs184/hw3/CBbunny_screenshot_3-20_5-2-12_rate-800.webp 800w,/assets/img/cs184/hw3/CBbunny_screenshot_3-20_5-2-12_rate-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/cs184/hw3/CBbunny_screenshot_3-20_5-2-12_rate.png" width="100%" height="auto" alt="Adaptive Sampling Rate of Bunny Scene" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption">Adaptive Sampling Rate</div> </div> <div class="col"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs184/hw3/CBbunny_screenshot_3-20_5-2-12-480.webp 480w,/assets/img/cs184/hw3/CBbunny_screenshot_3-20_5-2-12-800.webp 800w,/assets/img/cs184/hw3/CBbunny_screenshot_3-20_5-2-12-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/cs184/hw3/CBbunny_screenshot_3-20_5-2-12.png" width="100%" height="auto" alt="Adaptive Sampling of Bunny Scene" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption">CBbunny(3708.8680s)(12216183223 rays)</div> </div> </div> <div class="row align-items-center text-center"> <div class="col"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs184/hw3/CBdragon_screenshot_3-20_5-5-4_rate-480.webp 480w,/assets/img/cs184/hw3/CBdragon_screenshot_3-20_5-5-4_rate-800.webp 800w,/assets/img/cs184/hw3/CBdragon_screenshot_3-20_5-5-4_rate-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/cs184/hw3/CBdragon_screenshot_3-20_5-5-4_rate.png" width="100%" height="auto" alt="Adaptive Sampling Rate of Dragon Scene" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption">Adaptive Sampling Rate</div> </div> <div class="col"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs184/hw3/CBdragon_screenshot_3-20_5-5-4-480.webp 480w,/assets/img/cs184/hw3/CBdragon_screenshot_3-20_5-5-4-800.webp 800w,/assets/img/cs184/hw3/CBdragon_screenshot_3-20_5-5-4-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/cs184/hw3/CBdragon_screenshot_3-20_5-5-4.png" width="100%" height="auto" alt="Adaptive Sampling of Dragon Scene" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption">CBdragon(4391.0515s)(12347391960 rays)</div> </div> </div> </div> </div> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> <d-bibliography src="/assets/bibliography/empty.bib"></d-bibliography> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Naman Shimoga Satish. </div> </footer> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?601a2d3465e2a52bec38b600518d5f70"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"about",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-blog",title:"blog",description:"",section:"Navigation",handler:()=>{window.location.href="/blog/"}},{id:"nav-projects",title:"projects",description:"A growing collection of your cool projects.",section:"Navigation",handler:()=>{window.location.href="/projects/"}},{id:"nav-cv",title:"cv",description:"Naman Satish's CV",section:"Navigation",handler:()=>{window.location.href="/cv/"}},{id:"post-computational-photography",title:"Computational Photography",description:"Experimenting with computational photography on vacation!",section:"Posts",handler:()=>{window.location.href="/blog/2024/computational-photography/"}},{id:"news-a-simple-inline-announcement",title:"A simple inline announcement.",description:"",section:"News"},{id:"news-a-long-announcement-with-details",title:"A long announcement with details",description:"",section:"News",handler:()=>{window.location.href="/news/announcement_2/"}},{id:"news-a-simple-inline-announcement-with-markdown-emoji-sparkles-smile",title:'A simple inline announcement with Markdown emoji! <img class="emoji" title=":sparkles:" alt=":sparkles:" src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png" height="20" width="20"> <img class="emoji" title=":smile:" alt=":smile:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f604.png" height="20" width="20">',description:"",section:"News"},{id:"projects-handshake-bot",title:"Handshake Bot",description:"Final Project in C106A : Introduction to Robotics",section:"Projects",handler:()=>{window.location.href="/projects/106a_final/"}},{id:"projects-apollo-augmenting-light-functions-to-simulate-wave-based-diffraction",title:"Apollo: Augmenting Light Functions to Simulate Wave-Based Diffraction",description:"Final Project in CS184 : Foundations of Computer Graphics",section:"Projects",handler:()=>{window.location.href="/projects/184_proposal/"}},{id:"projects-milestone-update-apollo-augmenting-light-functions-to-simulate-wave-based-diffraction",title:"Milestone Update, Apollo: Augmenting Light Functions to Simulate Wave-Based Diffraction",description:"Final Project in CS184 : Foundations of Computer Graphics",section:"Projects",handler:()=>{window.location.href="/projects/184_milestone/"}},{id:"projects-final-report-apollo-augmenting-light-functions-to-simulate-wave-based-diffraction",title:"Final Report, Apollo: Augmenting Light Functions to Simulate Wave-Based Diffraction",description:"Final Project in CS184 : Foundations of Computer Graphics",section:"Projects",handler:()=>{window.location.href="/projects/184_final/"}},{id:"projects-project-3-with-very-long-name",title:"project 3 with very long name",description:"a project that redirects to another website",section:"Projects",handler:()=>{window.location.href="/projects/3_project/"}},{id:"projects-project-4",title:"project 4",description:"another without an image",section:"Projects",handler:()=>{window.location.href="/projects/4_project/"}},{id:"projects-project-5",title:"project 5",description:"a project with a background image",section:"Projects",handler:()=>{window.location.href="/projects/5_project/"}},{id:"projects-project-6",title:"project 6",description:"a project with no image",section:"Projects",handler:()=>{window.location.href="/projects/6_project/"}},{id:"projects-project-7",title:"project 7",description:"with background image",section:"Projects",handler:()=>{window.location.href="/projects/7_project/"}},{id:"projects-project-8",title:"project 8",description:"an other project with a background image and giscus comments",section:"Projects",handler:()=>{window.location.href="/projects/8_project/"}},{id:"projects-project-9",title:"project 9",description:"another project with an image \ud83c\udf89",section:"Projects",handler:()=>{window.location.href="/projects/9_project/"}},{id:"projects-rasterizer",title:"Rasterizer",description:"Part of CS184 : Foundations of Computer Graphics",section:"Projects",handler:()=>{window.location.href="/projects/homework_1/"}},{id:"projects-bezier-curves-and-triangle-meshes",title:"Bezier Curves and Triangle Meshes",description:"Part of CS184 : Foundations of Computer Graphics",section:"Projects",handler:()=>{window.location.href="/projects/homework_2/"}},{id:"projects-path-tracing",title:"Path Tracing",description:"Part of CS184 : Foundations of Computer Graphics",section:"Projects",handler:()=>{window.location.href="/projects/homework_3/"}},{id:"projects-cloth-simulation",title:"Cloth Simulation",description:"Part of CS184 : Foundations of Computer Graphics",section:"Projects",handler:()=>{window.location.href="/projects/homework_4/"}},{id:"projects-prokudin-gorskii-photo-collection",title:"Prokudin-Gorskii Photo Collection",description:"Part of CS180 : Intro to Computer Vision and Computational Photography",section:"Projects",handler:()=>{window.location.href="/projects/proj_1/"}},{id:"projects-filters-amp-frequencies",title:"Filters & Frequencies",description:"Part of CS180 : Intro to Computer Vision and Computational Photography",section:"Projects",handler:()=>{window.location.href="/projects/proj_2/"}},{id:"projects-face-morphing",title:"Face Morphing",description:"Part of CS180 : Intro to Computer Vision and Computational Photography",section:"Projects",handler:()=>{window.location.href="/projects/proj_3/"}},{id:"projects-auto-stitching-and-photo-mosaics",title:"(Auto)Stitching and Photo Mosaics",description:"Part of CS180 : Intro to Computer Vision and Computational Photography",section:"Projects",handler:()=>{window.location.href="/projects/proj_4/"}},{id:"projects-diffusion-models",title:"Diffusion Models",description:"Part of CS180 : Intro to Computer Vision and Computational Photography",section:"Projects",handler:()=>{window.location.href="/projects/proj_5/"}},{id:"projects-neural-radiance-fields",title:"Neural Radiance Fields",description:"Final Project in CS180 : Intro to Computer Vision and Computational Photography",section:"Projects",handler:()=>{window.location.href="/projects/proj_final/"}},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%6E%61%6D%61%6E@%62%65%72%6B%65%6C%65%79.%63%6F%6D","_blank")}},{id:"socials-google-scholar",title:"Google Scholar",section:"Socials",handler:()=>{window.open("https://scholar.google.com/citations?user=qc6CJjYAAAAJ","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>